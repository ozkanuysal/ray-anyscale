{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88fb2669",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import s3fs\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from diffusers import DDPMScheduler, UNet2DConditionModel\n",
    "from lightning.pytorch.utilities.types import OptimizerLRScheduler\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "import ray.train\n",
    "from ray.train.lightning import (\n",
    "    RayDDPStrategy,\n",
    "    RayLightningEnvironment,\n",
    "    RayTrainReportCallback,\n",
    ")\n",
    "from ray.train.torch import TorchTrainer, get_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "358ab518",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParquetDataset(Dataset):\n",
    "    \"\"\"Minimal PyTorch Dataset for data stored in parquet.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        s3_path: str,\n",
    "        dtype: np.dtype = np.float16,\n",
    "    ):\n",
    "        self.columns = [\"image_latents_256\", \"caption_latents\"]\n",
    "        loaded_df = pd.read_parquet(\n",
    "            s3_path,\n",
    "            columns=[\"image_latents_256\", \"caption_latents\"],\n",
    "            filesystem=s3fs.S3FileSystem(anon=False),\n",
    "        )\n",
    "        loaded_df[\"image_latents_256\"] = loaded_df[\"image_latents_256\"].apply(\n",
    "            lambda x: x.reshape(4, 32, 32).astype(dtype)\n",
    "        )\n",
    "        loaded_df[\"caption_latents\"] = loaded_df[\"caption_latents\"].apply(\n",
    "            lambda x: x.reshape(77, 1024).astype(dtype)\n",
    "        )\n",
    "        self.df = loaded_df\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        row = self.df.iloc[idx]\n",
    "        return {col: torch.as_tensor(row[col]) for col in self.columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d548da",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact_storage_path = os.environ[\"ANYSCALE_ARTIFACT_STORAGE\"]\n",
    "s3_path = f\"{artifact_storage_path}/stable-diffusion/256/6_000108_000000.parquet\"\n",
    "dataset = ParquetDataset(s3_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2abcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=8,  # Adjust based on memory constraints\n",
    "    shuffle=True,\n",
    "    num_workers=2,  # Adjust based on system's CPU cores\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d4f4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in data_loader:\n",
    "    print(batch[\"image_latents_256\"].shape, batch[\"caption_latents\"].shape)\n",
    "    print(batch[\"caption_latents\"].dtype, batch[\"image_latents_256\"].dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feff6291",
   "metadata": {},
   "source": [
    "### Stable difussion model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73b577b",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_unet_model_config = {\n",
    "    \"_class_name\": \"UNet2DConditionModel\",\n",
    "    \"_diffusers_version\": \"0.2.2\",\n",
    "    \"act_fn\": \"silu\",\n",
    "    \"attention_head_dim\": 8,\n",
    "    \"block_out_channels\": [160, 320, 640, 640],\n",
    "    \"center_input_sample\": False,\n",
    "    \"cross_attention_dim\": 1024,\n",
    "    \"down_block_types\": [\n",
    "        \"CrossAttnDownBlock2D\",\n",
    "        \"CrossAttnDownBlock2D\",\n",
    "        \"CrossAttnDownBlock2D\",\n",
    "        \"DownBlock2D\",\n",
    "    ],\n",
    "    \"downsample_padding\": 1,\n",
    "    \"flip_sin_to_cos\": True,\n",
    "    \"freq_shift\": 0,\n",
    "    \"in_channels\": 4,\n",
    "    \"layers_per_block\": 2,\n",
    "    \"mid_block_scale_factor\": 1,\n",
    "    \"norm_eps\": 1e-05,\n",
    "    \"norm_num_groups\": 32,\n",
    "    \"out_channels\": 4,\n",
    "    \"sample_size\": 64,\n",
    "    \"up_block_types\": [\n",
    "        \"UpBlock2D\",\n",
    "        \"CrossAttnUpBlock2D\",\n",
    "        \"CrossAttnUpBlock2D\",\n",
    "        \"CrossAttnUpBlock2D\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "class StableDiffusion(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        lr: float,\n",
    "        resolution: int,\n",
    "        weight_decay: float,\n",
    "        num_warmup_steps: int,\n",
    "        model_name: str,\n",
    "    ) -> None:\n",
    "        self.lr = lr\n",
    "        self.resolution = resolution\n",
    "        self.weight_decay = weight_decay\n",
    "        self.num_warmup_steps = num_warmup_steps\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        # Initialize U-Net.\n",
    "        # model_config = PretrainedConfig.get_config_dict(model_name, subfolder=\"unet\")[0]\n",
    "        model_config = small_unet_model_config\n",
    "        self.unet = UNet2DConditionModel(**model_config)\n",
    "        # Define the training noise scheduler.\n",
    "        self.noise_scheduler = DDPMScheduler.from_pretrained(\n",
    "            model_name, subfolder=\"scheduler\"\n",
    "        )\n",
    "        # Setup loss function.\n",
    "        self.loss_fn = F.mse_loss\n",
    "        self.current_training_steps = 0\n",
    "\n",
    "    def on_fit_start(self) -> None:\n",
    "        \"\"\"Move cumprod tensor to GPU in advance to avoid data movement on each step.\"\"\"\n",
    "        self.noise_scheduler.alphas_cumprod = self.noise_scheduler.alphas_cumprod.to(\n",
    "            get_device()\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self, batch: dict[str, torch.Tensor]\n",
    "    ) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Forward pass of the model.\"\"\"\n",
    "        # Extract inputs.\n",
    "        latents = batch[\"image_latents_256\"]\n",
    "        conditioning = batch[\"caption_latents\"]\n",
    "        # Sample the diffusion timesteps.\n",
    "        timesteps = self._sample_timesteps(latents)\n",
    "        # Add noise to the inputs (forward diffusion).\n",
    "        noise = torch.randn_like(latents)\n",
    "        noised_latents = self.noise_scheduler.add_noise(latents, noise, timesteps)\n",
    "        # Forward through the model.\n",
    "        outputs = self.unet(noised_latents, timesteps, conditioning)[\"sample\"]\n",
    "        return outputs, noise\n",
    "\n",
    "    def training_step(\n",
    "        self, batch: dict[str, torch.Tensor], batch_idx: int\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Training step of the model.\"\"\"\n",
    "        outputs, targets = self.forward(batch)\n",
    "        loss = self.loss_fn(outputs, targets)\n",
    "        self.log(\n",
    "            \"train/loss_mse\", loss.item(), prog_bar=False, on_step=True, sync_dist=False\n",
    "        )\n",
    "        self.current_training_steps += 1\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self) -> OptimizerLRScheduler:\n",
    "        \"\"\"Configure the optimizer and learning rate scheduler.\"\"\"\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            self.trainer.model.parameters(),\n",
    "            lr=self.lr,\n",
    "            weight_decay=self.weight_decay,\n",
    "        )\n",
    "        # Set a large training step here to keep lr constant after warm-up.\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=self.num_warmup_steps,\n",
    "            num_training_steps=100000000000,\n",
    "        )\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"interval\": \"step\",\n",
    "                \"frequency\": 1,\n",
    "            },\n",
    "        }\n",
    "\n",
    "    def _sample_timesteps(self, latents: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.randint(\n",
    "            0, len(self.noise_scheduler), (latents.shape[0],), device=latents.device\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904b9a46",
   "metadata": {},
   "source": [
    "### Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921f35a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lightning_training_loop(\n",
    "    train_loader: torch.utils.data.DataLoader,\n",
    "    storage_path: str,\n",
    "    model_name: str = \"stabilityai/stable-diffusion-2-base\",\n",
    "    resolution: int = 256,\n",
    "    lr: float = 1e-4,\n",
    "    max_epochs: int = 1,\n",
    "    num_warmup_steps: int = 10_000,\n",
    "    weight_decay: float = 1e-2,\n",
    ") -> None:\n",
    "    # 1. Initialize the model\n",
    "    model = StableDiffusion(\n",
    "        model_name=model_name,\n",
    "        resolution=resolution,\n",
    "        lr=lr,\n",
    "        num_warmup_steps=num_warmup_steps,\n",
    "        weight_decay=weight_decay,\n",
    "    )\n",
    "\n",
    "    # 2. Initialize the Lightning Trainer\n",
    "    trainer = pl.Trainer(\n",
    "        accelerator=\"gpu\",\n",
    "        devices=\"auto\",\n",
    "        precision=\"bf16-mixed\",\n",
    "        max_epochs=max_epochs,\n",
    "        default_root_dir=storage_path,\n",
    "        log_every_n_steps=8,\n",
    "    )\n",
    "\n",
    "    # 3. Run the trainer\n",
    "    trainer.fit(model=model, train_dataloaders=train_loader)\n",
    "\n",
    "storage_path = \"/mnt/local_storage/lightning/stable-diffusion-pretraining/\"\n",
    "lightning_training_loop(train_loader=data_loader, storage_path=storage_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9db443",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f19bed83",
   "metadata": {},
   "source": [
    "### DDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa11243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop_per_worker(\n",
    "    config: dict,  # Update the function signature to comply with Ray Train\n",
    "):\n",
    "    # Note lightning prepares the dataloader (adding a distributed sampler) for us\n",
    "    train_dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=config[\"batch_size_per_worker\"],\n",
    "        shuffle=True,\n",
    "        num_workers=2,\n",
    "    )\n",
    "\n",
    "    # Same model initialization as vanilla lightning\n",
    "    model = StableDiffusion(\n",
    "        lr=config[\"lr\"],\n",
    "        resolution=config[\"resolution\"],\n",
    "        weight_decay=config[\"weight_decay\"],\n",
    "        num_warmup_steps=config[\"num_warmup_steps\"],\n",
    "        model_name=config[\"model_name\"],\n",
    "    )\n",
    "\n",
    "    # Same trainer setup as vanilla lightning except we add Ray Train specific arguments\n",
    "    trainer = pl.Trainer(\n",
    "        max_steps=config[\"max_steps\"],\n",
    "        max_epochs=config[\"max_epochs\"],\n",
    "        accelerator=\"gpu\",\n",
    "        precision=\"bf16-mixed\",\n",
    "        devices=\"auto\",  # Set devices to \"auto\" to use all available GPUs\n",
    "        strategy=RayDDPStrategy(),  # Use RayDDPStrategy for distributed data parallel training\n",
    "        plugins=[\n",
    "            RayLightningEnvironment()\n",
    "        ],  # Use RayLightningEnvironment to run the Lightning Trainer\n",
    "        callbacks=[\n",
    "            RayTrainReportCallback()\n",
    "        ],  # Use RayTrainReportCallback to report metrics and checkpoints\n",
    "        enable_checkpointing=False,  # Disable lightning checkpointing\n",
    "    )\n",
    "\n",
    "    # 4. Same as vanilla lightning\n",
    "    trainer.fit(model, train_dataloaders=train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b7b1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_config = ray.train.ScalingConfig(num_workers=2, use_gpu=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8b4932",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_path = \"/mnt/cluster_storage/\"\n",
    "experiment_name = \"stable-diffusion-pretraining\"\n",
    "\n",
    "run_config = ray.train.RunConfig(name=experiment_name, storage_path=storage_path)\n",
    "\n",
    "train_loop_config = {\n",
    "    \"batch_size_per_worker\": 8,\n",
    "    \"prefetch_batches\": 1,\n",
    "    \"lr\": 0.0001,\n",
    "    \"num_warmup_steps\": 10_000,\n",
    "    \"weight_decay\": 0.01,\n",
    "    \"max_steps\": 550_000,\n",
    "    \"max_epochs\": 1,\n",
    "    \"resolution\": 256,\n",
    "    \"model_name\": \"stabilityai/stable-diffusion-2-base\",\n",
    "}\n",
    "\n",
    "trainer = TorchTrainer(\n",
    "    train_loop_per_worker,\n",
    "    train_loop_config=train_loop_config,\n",
    "    scaling_config=scaling_config,\n",
    "    run_config=run_config,\n",
    ")\n",
    "\n",
    "\n",
    "result = trainer.fit()\n",
    "print(f\"Training completed with result: {result}\")\n",
    "result.metrics_dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835241dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = result.checkpoint\n",
    "with ckpt.as_directory() as ckpt_dir:\n",
    "    ckpt_path = os.path.join(ckpt_dir, \"checkpoint.ckpt\")\n",
    "    loaded_model_ray_train = StableDiffusion.load_from_checkpoint(\n",
    "        checkpoint_path=ckpt_path,\n",
    "        map_location=torch.device(\"cpu\"),\n",
    "        weights_only=True,\n",
    "    )\n",
    "    loaded_model_ray_train.eval()\n",
    "\n",
    "loaded_model_ray_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580cc54a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ray-jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
